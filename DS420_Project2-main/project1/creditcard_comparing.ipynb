{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "752f3b61-731c-4d25-9a07-3bb16f36198a",
   "metadata": {},
   "source": [
    "# Algorithm Comparison\n",
    "\n",
    "##### Authors: Cody, Mateus and Mughees\n",
    "##### Step 5: Compare Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095aece8-dfb3-4844-a52f-adfa1a857df9",
   "metadata": {},
   "source": [
    "## Comparisons\n",
    "\n",
    "After comparing the performance on the machine learning algorithms Random Forest, K-nearest Neighbors, and Decision Tree, we analyze the best hyperparameters to determine which algorithm performs the best for the Credit Card dataset. \n",
    "<br>\n",
    "For the best hyperparameters the results for each algorithm are in order first to last. \n",
    "<br>\n",
    "\n",
    "Random Forest Algorithm\n",
    "* Accuracy: 0.9998417248474404\n",
    "* Precision: 0.9996841772818191\n",
    "* Recall: 1.0\n",
    "* F1 Score: 0.999842063700974\n",
    "<br>\n",
    "\n",
    "\n",
    "K-Nearest Neighbors Algorithm\n",
    "* Accuracy: 0.9997087822939634\n",
    "* Precision: 1.0\n",
    "* Recall: 0.8205128205128205\n",
    "* F1 Score: 0.9014084507042254\n",
    "<br>\n",
    "\n",
    "\n",
    "Decision Tree Algorithm\n",
    "* Accuracy: 0.9983293178340925\n",
    "* Precision: 0.9975114787424205\n",
    "* Recall: 0.999157421710434\n",
    "* F1 Score: 0.9983337718144348\n",
    "<br>\n",
    "\n",
    "Based on these results:\n",
    "* Accuracy: Random Forest achieves the highest accuracy, followed closely by K-Nearest Neighbors, and then Decision Tree.\n",
    "* Precision: K-Nearest Neighbors achieves the highest precision, indicating it has the lowest false positive rate. Random Forest follows closely, and Decision Tree has slightly lower precision.\n",
    "* Recall: Random Forest achieves perfect recall, indicating it captures all positive instances correctly. However, K-Nearest Neighbors has lower recall compared to the other two algorithms.\n",
    "* F1 Score: Random Forest also achieves the highest F1 score, followed by Decision Tree and then K-Nearest Neighbors.\n",
    "<br>\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "<p> For our dataset, since we have a 50%-50% division between classes, Accuracy is the best metric to use while judging the performance of different algorithms. Based on our results, Random Forest achieves the highest accuracy, so that is the best algorithm for this data set.</p>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS420 (Python3.8)",
   "language": "python",
   "name": "ds420"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

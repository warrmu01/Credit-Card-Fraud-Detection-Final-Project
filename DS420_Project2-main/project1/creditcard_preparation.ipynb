{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data\n",
    "\n",
    "##### Authors: Cody, Mateus, and Mughees\n",
    "##### Step 2: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "import ssl\n",
    "\n",
    "# may be needed to retrieve data\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2; based on housing_transformer_pipeline file\n",
    "\n",
    "def load_creditcard_data(drop_id = True):\n",
    "    \n",
    "    base_file = \"https://github.com/rohdma02/DS420_Project/blob/main/data/creditcard_2023_1.csv?raw=True\"\n",
    "    \n",
    "    additional_files = [\"https://github.com/rohdma02/DS420_Project/blob/main/data/creditcard_2023_2.csv?raw=True\",\n",
    "             \"https://github.com/rohdma02/DS420_Project/blob/main/data/creditcard_2023_3.csv?raw=True\",\n",
    "             \"https://github.com/rohdma02/DS420_Project/blob/main/data/creditcard_2023_4.csv?raw=True\"]\n",
    "    \n",
    "    df = pd.read_csv(base_file)\n",
    "    \n",
    "    for url in additional_files:\n",
    "        \n",
    "        more_rows = pd.read_csv(url)\n",
    "        \n",
    "        df = pd.concat([df, more_rows])\n",
    "        \n",
    "    if drop_id:\n",
    "        return df.drop(['id'], axis=1)\n",
    "    else:\n",
    "        return df\n",
    "    \n",
    "\n",
    "def create_creditcard_pipeline():\n",
    "\n",
    "    features = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "                'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19',\n",
    "                'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28',\n",
    "                'Amount']\n",
    "    \n",
    "    categorical_features = []\n",
    "\n",
    "\n",
    "    # Create a transformer pipeline\n",
    "    features_transformer = Pipeline(steps=[('imputer', SimpleImputer(\n",
    "        strategy='median')), ('scaler', StandardScaler())])\n",
    "\n",
    "    # Create a cat transformer pipeline\n",
    "    categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(\n",
    "        strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', features_transformer, features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "    # Create the final pipeline\n",
    "    # add more steps later as we work on the model\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def split_creditcard_data(data, ratios):\n",
    "\n",
    "    # Shuffle data\n",
    "\n",
    "    randomized_data = data.sample(frac = 1, random_state=1)\n",
    "\n",
    "\n",
    "    if 'id' in randomized_data.columns:\n",
    "\n",
    "        randomized_data = randomized_data.drop(['id'], axis=1)\n",
    "\n",
    "\n",
    "    X = randomized_data.drop(['Class'], axis=1)\n",
    "    y = randomized_data['Class']\n",
    "\n",
    "    \n",
    "    # Get ratios from tuple\n",
    "    dev_ratio = ratios[0]\n",
    "    test_ratio = ratios[1]\n",
    "    \n",
    "    # Determine size of sets using given ratios\n",
    "    devset_size = int(dev_ratio * X.shape[0])\n",
    "    testset_size = int(test_ratio * X.shape[0])\n",
    "    \n",
    "    \n",
    "    # Take data points up to number needed for devset as training set\n",
    "    X_train = X[:-(devset_size+testset_size)]\n",
    "    y_train = y[:-(devset_size+testset_size)]\n",
    "    \n",
    "    \n",
    "    # Take devset_size data points before testset_size data points for dev set\n",
    "    X_dev = X[-(devset_size+testset_size):-testset_size]\n",
    "    y_dev = y[-(devset_size+testset_size):-testset_size]\n",
    "    \n",
    "    \n",
    "    #Take last testset_size data points as test set\n",
    "    X_test = X[-testset_size:]\n",
    "    y_test = y[-testset_size:]\n",
    "    \n",
    "\n",
    "    return X_train, X_dev, X_test, y_train, y_dev, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_creditcard_data(ratios):\n",
    "\n",
    "    creditcard_data = load_creditcard_data()\n",
    "    \n",
    "    return split_creditcard_data(creditcard_data, ratios)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
